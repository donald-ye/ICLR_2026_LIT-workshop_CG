# -*- coding: utf-8 -*-
"""ICLR workshop pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wixklk-vQIHRXmY4guIDWWDwX3VPr0OP

Full Pipeline Gradients vs Causal Importance ICLR LIT workshop code submission
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from collections import Counter
from matplotlib.patches import Patch
import pickle, os

# Setup
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

output_dir = './results'
os.makedirs(output_dir, exist_ok=True)

# CONFIG
PAD, START, SEP, END = 100, 101, 102, 103
config = {"d_model": 128, "n_heads": 4, "d_ff": 512, "n_layers": 4, "vocab_size": 104,
          "batch_size": 64, "lr": 1e-3, "max_train_steps": 15000, "target_train_acc": 0.90,
          "eval_every": 500, "ood_min_acc": 0.20, "ood_max_acc": 0.75}
SEEDS = [42, 123, 456, 789, 1010, 2020, 3030, 4040, 5050, 6060]
TRAIN_MIN, TRAIN_MAX = 3, 7

"""**A)** Model and Helper functions"""

# MODEL
class MultiHeadAttention(nn.Module):
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.n_heads, self.d_head = n_heads, d_model // n_heads
        self.W_q, self.W_k, self.W_v, self.W_o = [nn.Linear(d_model, d_model) for _ in range(4)]
        self.head_outputs = []
    def forward(self, x, mask=None):
        B, T, D = x.shape
        Q = self.W_q(x).view(B, T, self.n_heads, self.d_head).transpose(1, 2)
        K = self.W_k(x).view(B, T, self.n_heads, self.d_head).transpose(1, 2)
        V = self.W_v(x).view(B, T, self.n_heads, self.d_head).transpose(1, 2)
        scores = (Q @ K.transpose(-2, -1)) / (self.d_head ** 0.5)
        if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)
        attn = F.softmax(scores, dim=-1)
        head_out = attn @ V
        self.head_outputs = [head_out[:, i] for i in range(self.n_heads)]
        return self.W_o(head_out.transpose(1, 2).contiguous().view(B, T, D))

class TransformerBlock(nn.Module):
    def __init__(self, d_model, n_heads, d_ff):
        super().__init__()
        self.ln1, self.ln2 = nn.LayerNorm(d_model), nn.LayerNorm(d_model)
        self.attn = MultiHeadAttention(d_model, n_heads)
        self.mlp = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Linear(d_ff, d_model))
    def forward(self, x, mask=None):
        x = x + self.attn(self.ln1(x), mask)
        return x + self.mlp(self.ln2(x))

class Transformer(nn.Module):
    def __init__(self):
        super().__init__()
        self.embed = nn.Embedding(config["vocab_size"], config["d_model"])
        self.blocks = nn.ModuleList([TransformerBlock(config["d_model"], config["n_heads"], config["d_ff"]) for _ in range(config["n_layers"])])
        self.ln_f, self.out = nn.LayerNorm(config["d_model"]), nn.Linear(config["d_model"], config["vocab_size"])
    def forward(self, x, mask=None):
        x = self.embed(x)
        for block in self.blocks: x = block(x, mask)
        return self.out(self.ln_f(x))
    def get_mask(self, seq_len):
        return torch.tril(torch.ones(seq_len, seq_len, device=device)).unsqueeze(0).unsqueeze(0)

# HELPER FUNCTIONS
def make_batch(batch_size, min_len, max_len, task):
    inputs, targets = [], []
    for _ in range(batch_size):
        length = np.random.randint(min_len, max_len + 1)
        nums = np.random.randint(1, 100, size=length).tolist()
        inputs.append([START] + nums + [SEP])
        targets.append((nums[::-1] if task == "reverse" else sorted(nums)) + [END])
    max_inp, max_tgt = max(len(x) for x in inputs), max(len(x) for x in targets)
    inputs = [x + [PAD] * (max_inp - len(x)) for x in inputs]
    targets = [x + [PAD] * (max_tgt - len(x)) for x in targets]
    return torch.tensor(inputs, device=device), torch.tensor(targets, device=device)

def compute_accuracy(model, min_len, max_len, task, n_samples=100):
    model.eval()
    correct = 0
    with torch.no_grad():
        for _ in range(n_samples):
            inp, tgt = make_batch(1, min_len, max_len, task)
            generated = inp.clone()
            for _ in range(tgt.size(1)):
                logits = model(generated, model.get_mask(generated.size(1)))
                generated = torch.cat([generated, logits[:, -1].argmax(-1, keepdim=True)], dim=1)
            if generated[0, inp.size(1):inp.size(1)+tgt.size(1)].tolist() == tgt[0].tolist(): correct += 1
    model.train()
    return correct / n_samples

def train_model(model, optimizer, task):
    model.train()
    for step in range(config["max_train_steps"]):
        inp, tgt = make_batch(config["batch_size"], TRAIN_MIN, TRAIN_MAX, task)
        dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
        logits = model(dec_inp, model.get_mask(dec_inp.size(1)))
        loss = F.cross_entropy(logits[:, inp.size(1)-1:inp.size(1)-1+tgt.size(1)].reshape(-1, config["vocab_size"]), tgt.reshape(-1), ignore_index=PAD)
        optimizer.zero_grad(); loss.backward(); optimizer.step()
        if (step + 1) % config["eval_every"] == 0:
            acc = compute_accuracy(model, TRAIN_MIN, TRAIN_MAX, task)
            if acc >= config["target_train_acc"]: return step + 1, acc
    return config["max_train_steps"], compute_accuracy(model, TRAIN_MIN, TRAIN_MAX, task)

def find_ood_length(model, task):
    for test_len in [8, 9, 10, 11]:
        acc = compute_accuracy(model, test_len, test_len, task)
        if config["ood_min_acc"] <= acc <= config["ood_max_acc"]: return test_len, acc
    return None, None

def measure_gradients(model, optimizer, test_len, task):
    grads = {f"L{l}_H{h}": [] for l in range(4) for h in range(4)}
    grads.update({f"L{l}_MLP": [] for l in range(4)})
    model.train()
    for _ in range(50):
        inp, tgt = make_batch(config["batch_size"], test_len, test_len, task)
        dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
        logits = model(dec_inp, model.get_mask(dec_inp.size(1)))
        loss = F.cross_entropy(logits[:, inp.size(1)-1:inp.size(1)-1+tgt.size(1)].reshape(-1, config["vocab_size"]), tgt.reshape(-1), ignore_index=PAD)
        optimizer.zero_grad(); loss.backward()
        for l, block in enumerate(model.blocks):
            d_head = config["d_model"] // config["n_heads"]
            for h in range(4): grads[f"L{l}_H{h}"].append(block.attn.W_v.weight.grad[h*d_head:(h+1)*d_head, :].norm().item())
            grads[f"L{l}_MLP"].append(block.mlp[2].weight.grad.norm().item())
    return {k: np.mean(v) for k, v in grads.items()}

def measure_causal(model, baseline_acc, test_len, task):
    means = {f"L{l}_H{h}": [] for l in range(4) for h in range(4)}
    means.update({f"L{l}_MLP": [] for l in range(4)})
    model.eval()
    with torch.no_grad():
        for _ in range(50):
            inp, tgt = make_batch(config["batch_size"], test_len, test_len, task)
            dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
            x = model.embed(dec_inp)
            for l, block in enumerate(model.blocks):
                x = x + block.attn(block.ln1(x), model.get_mask(dec_inp.size(1)))
                for h, ho in enumerate(block.attn.head_outputs): means[f"L{l}_H{h}"].append(ho.mean(dim=(0,1)).cpu())
                mlp_out = block.mlp(block.ln2(x))
                means[f"L{l}_MLP"].append(mlp_out.mean(dim=(0,1)).cpu())
                x = x + mlp_out
    means = {k: torch.stack(v).mean(0).to(device) for k, v in means.items()}

    effects = {}
    for l in range(4):
        for h in range(4):
            name = f"L{l}_H{h}"
            effects[name] = baseline_acc - ablate_eval(model, l, "head", h, means[name], test_len, task)
        name = f"L{l}_MLP"
        effects[name] = baseline_acc - ablate_eval(model, l, "mlp", None, means[name], test_len, task)
    return effects, means

def ablate_eval(model, ablate_l, ablate_type, ablate_h, ablation_val, test_len, task, n=100):
    model.eval()
    correct = 0
    with torch.no_grad():
        for _ in range(n):
            inp, tgt = make_batch(1, test_len, test_len, task)
            generated = inp.clone()
            for _ in range(tgt.size(1)):
                x = model.embed(generated)
                for l, block in enumerate(model.blocks):
                    attn_out = block.attn(block.ln1(x), model.get_mask(generated.size(1)))
                    if l == ablate_l and ablate_type == "head":
                        B, T, D = x.shape
                        d_head = D // 4
                        attn_out = attn_out.view(B, T, 4, d_head)
                        attn_out[:, :, ablate_h, :] = ablation_val
                        attn_out = attn_out.view(B, T, D)
                    x = x + attn_out
                    mlp_out = block.mlp(block.ln2(x))
                    if l == ablate_l and ablate_type == "mlp":
                        mlp_out = ablation_val.unsqueeze(0).unsqueeze(0).expand_as(mlp_out)
                    x = x + mlp_out
                logits = model.out(model.ln_f(x))
                generated = torch.cat([generated, logits[:, -1].argmax(-1, keepdim=True)], dim=1)
            if generated[0, inp.size(1):inp.size(1)+tgt.size(1)].tolist() == tgt[0].tolist(): correct += 1
    return correct / n

def classify(g_rank, c_rank, n=20):
    diff = g_rank - c_rank
    return "hidden_hero" if diff < -n*0.3 else ("gradient_bloat" if diff > n*0.3 else "aligned")

"""**B)** Experiments"""

# EXPERIMENTS FOR BOTH TASKS

def run_experiment(task):
    print(f"\n{'='*60}\n{task.upper()} TASK EXPERIMENT\n{'='*60}")
    results, skipped = [], []
    for i, seed in enumerate(SEEDS):
        print(f"\nSEED {seed} ({i+1}/{len(SEEDS)})")
        torch.manual_seed(seed); np.random.seed(seed)
        model = Transformer().to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=config["lr"])
        steps, train_acc = train_model(model, optimizer, task)
        test_len, ood_acc = find_ood_length(model, task)
        if test_len is None: skipped.append(seed); continue
        print(f"  OOD len={test_len}, acc={ood_acc:.0%}")
        grads = measure_gradients(model, optimizer, test_len, task)
        causal, means = measure_causal(model, ood_acc, test_len, task)
        comps = sorted(grads.keys())
        G, C = np.array([grads[c] for c in comps]), np.array([causal[c] for c in comps])
        G_rank, C_rank = stats.rankdata(G), stats.rankdata(C)
        rho, _ = stats.spearmanr(G, C)
        types = {c: classify(G_rank[j], C_rank[j]) for j, c in enumerate(comps)}
        heroes = [(c, G[j], C[j]) for j, c in enumerate(comps) if types[c] == "hidden_hero"]
        bloats = [(c, G[j], C[j]) for j, c in enumerate(comps) if types[c] == "gradient_bloat"]
        print(f"  ρ={rho:.3f}, Heroes={len(heroes)}, Bloats={len(bloats)}")
        results.append({"seed": seed, "test_len": test_len, "ood_acc": ood_acc, "rho": rho,
                        "heroes": heroes, "bloats": bloats, "types": types, "grads": grads,
                        "causal": causal, "G_rank": G_rank, "C_rank": C_rank, "means": means})
    return results, skipped

reverse_results, rev_skipped = run_experiment("reverse")
sort_results, sort_skipped = run_experiment("sort")

# Save results
with open(f"{output_dir}/all_results.pkl", 'wb') as f:
    pickle.dump({"reverse": reverse_results, "sort": sort_results}, f)
print(f"\nSaved results to {output_dir}/all_results.pkl")

"""**C)** Pruning"""

# PRUNING SIMULATION - BOTH TASKS

print(f"\n{'='*60}\nPRUNING SIMULATION\n{'='*60}")

def run_pruning_experiment(results, task_name):
    best = max(results, key=lambda r: len(r["heroes"]) + len(r["bloats"]))
    if len(best["heroes"]) < 2 or len(best["bloats"]) < 2:
        for r in sorted(results, key=lambda r: len(r["heroes"]) + len(r["bloats"]), reverse=True):
            if len(r["heroes"]) >= 2 and len(r["bloats"]) >= 2:
                best = r; break

    print(f"\n{task_name.upper()}: Seed {best['seed']} ({len(best['heroes'])} heroes, {len(best['bloats'])} bloats)")
    torch.manual_seed(best["seed"]); np.random.seed(best["seed"])
    model = Transformer().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=config["lr"])
    train_model(model, optimizer, task_name)

    test_len = best["test_len"]
    baseline_acc = compute_accuracy(model, test_len, test_len, task_name, 200)
    _, means = measure_causal(model, baseline_acc, test_len, task_name)

    def prune_eval(comps_to_prune):
        model.eval()
        correct = 0
        with torch.no_grad():
            for _ in range(200):
                inp, tgt = make_batch(1, test_len, test_len, task_name)
                generated = inp.clone()
                for _ in range(tgt.size(1)):
                    x = model.embed(generated)
                    for l, block in enumerate(model.blocks):
                        attn_out = block.attn(block.ln1(x), model.get_mask(generated.size(1)))
                        for h in range(4):
                            if f"L{l}_H{h}" in comps_to_prune:
                                B, T, D = x.shape
                                attn_out = attn_out.view(B, T, 4, D//4)
                                attn_out[:, :, h, :] = means[f"L{l}_H{h}"]
                                attn_out = attn_out.view(B, T, D)
                        x = x + attn_out
                        mlp_out = block.mlp(block.ln2(x))
                        if f"L{l}_MLP" in comps_to_prune:
                            mlp_out = means[f"L{l}_MLP"].unsqueeze(0).unsqueeze(0).expand_as(mlp_out)
                        x = x + mlp_out
                    logits = model.out(model.ln_f(x))
                    generated = torch.cat([generated, logits[:, -1].argmax(-1, keepdim=True)], dim=1)
                if generated[0, inp.size(1):inp.size(1)+tgt.size(1)].tolist() == tgt[0].tolist(): correct += 1
        return correct / 200

    bloats = [b[0] for b in best["bloats"]][:2]
    heroes = [h[0] for h in best["heroes"]][:2]
    acc_bloats, acc_heroes = prune_eval(bloats), prune_eval(heroes)

    print(f"  Baseline: {baseline_acc:.1%}, Prune bloats: {acc_bloats:.1%}, Prune heroes: {acc_heroes:.1%}")
    return {"task": task_name, "seed": best["seed"], "baseline": baseline_acc, "bloats": bloats,
            "heroes": heroes, "acc_bloats": acc_bloats, "acc_heroes": acc_heroes, "rho": best["rho"]}

reverse_pruning = run_pruning_experiment(reverse_results, "reverse")
sort_pruning = run_pruning_experiment(sort_results, "sort")

with open(f"{output_dir}/pruning_results.pkl", 'wb') as f:
    pickle.dump({"reverse": reverse_pruning, "sort": sort_pruning}, f)

"""**D)** Figures"""

import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
from matplotlib.patches import Patch

# Much larger global font sizes
plt.rcParams.update({
    'font.size': 40,
    'axes.titlesize': 44,
    'axes.labelsize': 42,
    'xtick.labelsize': 68,
    'ytick.labelsize': 68,
    'legend.fontsize': 98,
})

C_HERO, C_BLOAT, C_ALIGNED = '#2E7D32', '#C62828', '#757575'
C_BASE, C_WARN, C_DANGER = '#4CAF50', '#FF9800', '#F44336'
comps = sorted(reverse_results[0]["grads"].keys())
rev_rho = np.mean([r["rho"] for r in reverse_results])
sort_rho = np.mean([r["rho"] for r in sort_results])

def get_comp_summary(results):
    hh_counts = Counter([h[0] for r in results for h in r["heroes"]])
    gb_counts = Counter([b[0] for r in results for b in r["bloats"]])
    summary = []
    for c in comps:
        g_ranks = [r["G_rank"][comps.index(c)] for r in results]
        c_ranks = [r["C_rank"][comps.index(c)] for r in results]
        summary.append({"name": c, "rank_diff": np.mean(np.array(g_ranks) - np.array(c_ranks))})
    return sorted(summary, key=lambda x: x["rank_diff"]), hh_counts, gb_counts

rev_summary, rev_hh, rev_gb = get_comp_summary(reverse_results)
sort_summary, sort_hh, sort_gb = get_comp_summary(sort_results)

# FIGURE 1: Main (2x5 grid) - MUCH LARGER
fig, axes = plt.subplots(2, 5, figsize=(32, 16))
for row, (results, title) in enumerate([(reverse_results, "REVERSE"), (sort_results, "SORT")]):
    for col, r in enumerate(results[:5]):
        ax = axes[row, col]
        G = np.array([r["grads"][c] for c in comps])
        C = np.array([r["causal"][c] for c in comps])
        G_norm = (G - G.min()) / (G.max() - G.min() + 1e-8)
        C_norm = (C - C.min()) / (C.max() - C.min() + 1e-8)
        colors = [C_HERO if r["types"][c]=="hidden_hero" else C_BLOAT if r["types"][c]=="gradient_bloat" else C_ALIGNED for c in comps]
        ax.scatter(G_norm, C_norm, c=colors, s=500, alpha=0.8, edgecolors='black', linewidth=2.5)
        for i, c in enumerate(comps):
            if r["types"][c] in ["hidden_hero", "gradient_bloat"]:
                ax.annotate(c, (G_norm[i], C_norm[i]), fontsize=16, xytext=(6, 6), textcoords='offset points', fontweight='bold')
        ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=3)
        ax.set_xlim(-0.05, 1.15); ax.set_ylim(-0.05, 1.15)
        ax.set_title(f"Seed {r['seed']}\nρ={r['rho']:.2f}, OOD={r['ood_acc']:.0%}", fontsize=32, fontweight='bold')
        ax.set_xlabel("Gradient Magnitude" if row==1 else "", fontsize=32)
        ax.set_ylabel("Causal Importance" if col==0 else "", fontsize=32)
        ax.set_xticks([0, 0.5, 1.0])
        ax.set_yticks([0, 0.5, 1.0])
        ax.tick_params(axis='both', which='major', labelsize=30, width=2, length=8)
        ax.grid(True, alpha=0.3, linestyle='--')
        for spine in ax.spines.values():
            spine.set_linewidth(2)
    axes[row, 0].text(-0.55, 0.5, title, transform=axes[row, 0].transAxes, fontsize=32, fontweight='bold', va='center', rotation=90)

legend_elements = [Patch(facecolor=C_HERO, edgecolor='black', linewidth=2, label='Hidden Hero'),
                   Patch(facecolor=C_BLOAT, edgecolor='black', linewidth=2, label='Gradient Bloat'),
                   Patch(facecolor=C_ALIGNED, edgecolor='black', linewidth=2, label='Aligned')]
fig.legend(handles=legend_elements, loc='upper center', ncol=3, fontsize=48, bbox_to_anchor=(0.5, 1.02),
           handletextpad=1, columnspacing=2, frameon=True, edgecolor='black', fancybox=False)
fig.suptitle(f"Gradient vs Causal Importance: Reverse (ρ={rev_rho:.2f}) vs Sort (ρ={sort_rho:.2f})", fontsize=42, fontweight='bold', y=1.07)
plt.tight_layout()
plt.savefig(f"{output_dir}/figure1_correlation.pdf", dpi=300, bbox_inches='tight')
plt.savefig(f"{output_dir}/figure1_correlation.png", dpi=300, bbox_inches='tight')
print("Saved: figure1_correlation.pdf/png")

# FIGURE 2: Waterfall - MUCH LARGER
fig, axes = plt.subplots(1, 2, figsize=(22, 14))
for ax, (summary, title, rho) in zip(axes, [(rev_summary, "Reverse", rev_rho), (sort_summary, "Sort", sort_rho)]):
    names = [s["name"] for s in summary]
    diffs = [s["rank_diff"] for s in summary]
    colors = [C_HERO if d < -2 else C_BLOAT if d > 2 else C_ALIGNED for d in diffs]
    ax.barh(range(len(names)), diffs, color=colors, alpha=0.8, edgecolor='black', height=0.7, linewidth=2)
    ax.axvline(0, color='black', linewidth=3)
    ax.axvline(6, color=C_BLOAT, linestyle='--', alpha=0.7, linewidth=3)
    ax.axvline(-6, color=C_HERO, linestyle='--', alpha=0.7, linewidth=3)
    ax.set_yticks(range(len(names)))
    ax.set_yticklabels(names, fontsize=24, fontweight='bold')
    ax.set_xlabel("Mean Rank Difference (Gradient − Causal)", fontsize=24)
    ax.set_title(f"{title} Task (ρ={rho:.2f})", fontsize=24, fontweight='bold')
    ax.invert_yaxis()
    ax.grid(axis='x', alpha=0.3)
    ax.tick_params(axis='x', which='major', labelsize=28)

fig.suptitle("Layer-wise Gradient vs Causal Rank Difference\n← Undervalued (Heroes) | Overvalued (Bloats) →", fontsize=32, fontweight='bold')
plt.tight_layout()
plt.savefig(f"{output_dir}/figure2_waterfall.pdf", dpi=300, bbox_inches='tight')
plt.savefig(f"{output_dir}/figure2_waterfall.png", dpi=300, bbox_inches='tight')
print("Saved: figure2_waterfall.pdf/png")

# FIGURE 3: Pruning Comparison - MUCH LARGER
fig, axes = plt.subplots(1, 2, figsize=(22, 12))
for ax, data in zip(axes, [reverse_pruning, sort_pruning]):
    conditions = ['Baseline', f'Prune Bloats\n({", ".join(data["bloats"])})', f'Prune Heroes\n({", ".join(data["heroes"])})']
    accs = [data["baseline"]*100, data["acc_bloats"]*100, data["acc_heroes"]*100]
    bars = ax.bar(conditions, accs, color=[C_BASE, C_WARN, C_DANGER], edgecolor='black', linewidth=3, width=0.55)
    for bar, acc in zip(bars, accs):
        ax.annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),
                    xytext=(0, 10), textcoords="offset points", ha='center', va='bottom', fontsize=28, fontweight='bold')
    ax.annotate('', xy=(1, accs[1]), xytext=(1, accs[0]), arrowprops=dict(arrowstyle='<->', color='black', lw=3))
    ax.text(1.35, (accs[0]+accs[1])/2, f'Δ={accs[1]-accs[0]:.1f}%', fontsize=28, va='center', fontweight='bold')
    ax.annotate('', xy=(2, max(accs[2], 1)), xytext=(2, accs[0]), arrowprops=dict(arrowstyle='<->', color='black', lw=3))
    ax.text(2.35, (accs[0]+accs[2])/2, f'Δ={accs[2]-accs[0]:.1f}%', fontsize=28, va='center', fontweight='bold')
    ax.set_ylabel('OOD Accuracy (%)', fontsize=28)
    ax.set_ylim(0, max(accs)*1.4)
    ax.set_title(f'{data["task"].upper()} Task\nSeed {data["seed"]}, ρ={data["rho"]:.2f}', fontsize=30, fontweight='bold')
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.yaxis.grid(True, linestyle='--', alpha=0.3)
    ax.tick_params(axis='both', which='major', labelsize=24)

legend_elements = [Patch(facecolor=C_BASE, edgecolor='black', label='Baseline'),
                   Patch(facecolor=C_WARN, edgecolor='black', label='Prune Bloats (high gradient)'),
                   Patch(facecolor=C_DANGER, edgecolor='black', label='Prune Heroes (low gradient)')]
fig.legend(handles=legend_elements, loc='upper center', ncol=3, fontsize=28, bbox_to_anchor=(0.5, 1.02))
fig.suptitle('Pruning Impact on OOD Generalization', fontsize=36, fontweight='bold', y=1.08)
plt.tight_layout()
plt.savefig(f"{output_dir}/figure3_pruning.pdf", dpi=300, bbox_inches='tight')
plt.savefig(f"{output_dir}/figure3_pruning.png", dpi=300, bbox_inches='tight')
print("Saved: figure3_pruning.pdf/png")

# FIGURE APPENDIX: All 20 seeds - MUCH LARGER
fig, axes = plt.subplots(4, 5, figsize=(40, 36))
for idx, r in enumerate(reverse_results):
    row, col = idx // 5, idx % 5
    ax = axes[row, col]
    G = np.array([r["grads"][c] for c in comps]); C = np.array([r["causal"][c] for c in comps])
    G_norm = (G - G.min()) / (G.max() - G.min() + 1e-8); C_norm = (C - C.min()) / (C.max() - C.min() + 1e-8)
    colors = [C_HERO if r["types"][c]=="hidden_hero" else C_BLOAT if r["types"][c]=="gradient_bloat" else C_ALIGNED for c in comps]
    ax.scatter(G_norm, C_norm, c=colors, s=500, alpha=0.8, edgecolors='black', linewidth=2.5)
    for i, c in enumerate(comps):
        if r["types"][c] in ["hidden_hero", "gradient_bloat"]:
            ax.annotate(c, (G_norm[i], C_norm[i]), fontsize=16, xytext=(6, 6), textcoords='offset points', fontweight='bold')
    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=3)
    ax.set_xlim(-0.05, 1.15); ax.set_ylim(-0.05, 1.15)
    ax.set_title(f"REVERSE Seed {r['seed']}\nρ={r['rho']:.2f}", fontsize=28, fontweight='bold')
    ax.set_xlabel("Gradient", fontsize=26)
    ax.set_ylabel("Causal", fontsize=26)
    ax.set_xticks([0, 0.5, 1.0])
    ax.set_yticks([0, 0.5, 1.0])
    ax.tick_params(axis='both', which='major', labelsize=22, width=2, length=8)
    ax.grid(True, alpha=0.3, linestyle='--')
    for spine in ax.spines.values():
        spine.set_linewidth(2)

for idx, r in enumerate(sort_results):
    row, col = (idx // 5) + 2, idx % 5
    ax = axes[row, col]
    G = np.array([r["grads"][c] for c in comps]); C = np.array([r["causal"][c] for c in comps])
    G_norm = (G - G.min()) / (G.max() - G.min() + 1e-8); C_norm = (C - C.min()) / (C.max() - C.min() + 1e-8)
    colors = [C_HERO if r["types"][c]=="hidden_hero" else C_BLOAT if r["types"][c]=="gradient_bloat" else C_ALIGNED for c in comps]
    ax.scatter(G_norm, C_norm, c=colors, s=500, alpha=0.8, edgecolors='black', linewidth=2.5)
    for i, c in enumerate(comps):
        if r["types"][c] in ["hidden_hero", "gradient_bloat"]:
            ax.annotate(c, (G_norm[i], C_norm[i]), fontsize=16, xytext=(6, 6), textcoords='offset points', fontweight='bold')
    ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=3)
    ax.set_xlim(-0.05, 1.15); ax.set_ylim(-0.05, 1.15)
    ax.set_title(f"SORT Seed {r['seed']}\nρ={r['rho']:.2f}", fontsize=28, fontweight='bold')
    ax.set_xlabel("Gradient", fontsize=26)
    ax.set_ylabel("Causal", fontsize=26)
    ax.set_xticks([0, 0.5, 1.0])
    ax.set_yticks([0, 0.5, 1.0])
    ax.tick_params(axis='both', which='major', labelsize=22, width=2, length=8)
    ax.grid(True, alpha=0.3, linestyle='--')
    for spine in ax.spines.values():
        spine.set_linewidth(2)

legend_elements = [Patch(facecolor=C_HERO, edgecolor='black', linewidth=2, label='Hidden Hero'),
                   Patch(facecolor=C_BLOAT, edgecolor='black', linewidth=2, label='Gradient Bloat'),
                   Patch(facecolor=C_ALIGNED, edgecolor='black', linewidth=2, label='Aligned')]
fig.legend(handles=legend_elements, loc='upper center', ncol=3, fontsize=36, bbox_to_anchor=(0.5, 1.01),
           handletextpad=1, columnspacing=2, frameon=True, edgecolor='black', fancybox=False)
fig.suptitle(f"Appendix: All Seeds — Reverse (ρ={rev_rho:.2f}) vs Sort (ρ={sort_rho:.2f})", fontsize=38, fontweight='bold', y=1.03)
plt.tight_layout()
plt.savefig(f"{output_dir}/figure_appendix.pdf", dpi=300, bbox_inches='tight')
plt.savefig(f"{output_dir}/figure_appendix.png", dpi=300, bbox_inches='tight')
print("Saved: figure_appendix.pdf/png")

"""**E)** Pruning All seeds"""

def make_batch(batch_size, min_len, max_len): # Sort Task
    inputs, targets = [], []
    for _ in range(batch_size):
        length = np.random.randint(min_len, max_len + 1)
        nums = np.random.randint(1, 100, size=length).tolist()
        inputs.append([START] + nums + [SEP])
        targets.append(sorted(nums) + [END])
    max_inp, max_tgt = max(len(x) for x in inputs), max(len(x) for x in targets)
    inputs = [x + [PAD] * (max_inp - len(x)) for x in inputs]
    targets = [x + [PAD] * (max_tgt - len(x)) for x in targets]
    return torch.tensor(inputs, device=device), torch.tensor(targets, device=device)

def compute_accuracy(model, length, n_samples=100):
    model.eval()
    correct = 0
    with torch.no_grad():
        for _ in range(n_samples):
            inp, tgt = make_batch(1, length, length)
            generated = inp.clone()
            for _ in range(tgt.size(1)):
                logits = model(generated, model.get_mask(generated.size(1)))
                generated = torch.cat([generated, logits[:, -1].argmax(-1, keepdim=True)], dim=1)
            if generated[0, inp.size(1):inp.size(1)+tgt.size(1)].tolist() == tgt[0].tolist(): correct += 1
    return correct / n_samples

def train_one_seed(seed):
    torch.manual_seed(seed); np.random.seed(seed)
    model = Transformer().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=config["lr"])
    model.train()

    # Train
    for step in range(config["max_train_steps"]):
        inp, tgt = make_batch(config["batch_size"], 3, 7)
        dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
        logits = model(dec_inp, model.get_mask(dec_inp.size(1)))
        loss = F.cross_entropy(logits[:, inp.size(1)-1:inp.size(1)-1+tgt.size(1)].reshape(-1, config["vocab_size"]), tgt.reshape(-1), ignore_index=PAD)
        optimizer.zero_grad(); loss.backward(); optimizer.step()
        if (step+1) % config["eval_every"] == 0:
            if compute_accuracy(model, 7) >= config["target_train_acc"]: break

    # Find OOD Length (20-75% acc)
    ood_len, ood_acc = None, 0
    for length in [8, 9, 10, 11]:
        acc = compute_accuracy(model, length)
        if 0.20 <= acc <= 0.75:
            ood_len, ood_acc = length, acc
            break
    if ood_len is None: return None # Skip if no valid OOD length found

    # Measure Gradients
    grads = {}
    model.train() # Grads require train mode
    for _ in range(50):
        inp, tgt = make_batch(config["batch_size"], ood_len, ood_len)
        dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
        logits = model(dec_inp, model.get_mask(dec_inp.size(1)))
        loss = F.cross_entropy(logits[:, inp.size(1)-1:inp.size(1)-1+tgt.size(1)].reshape(-1, config["vocab_size"]), tgt.reshape(-1), ignore_index=PAD)
        optimizer.zero_grad(); loss.backward()
        for l, block in enumerate(model.blocks):
            for h in range(4): grads[f"L{l}_H{h}"] = grads.get(f"L{l}_H{h}", 0) + block.attn.W_v.weight.grad.norm().item()
    grads = {k: v/50 for k,v in grads.items()}

    # Measure Causal (Ablation) & Mean Acts
    model.eval()
    means, causal = {}, {}
    # Get Means
    with torch.no_grad():
        for _ in range(50):
            inp, tgt = make_batch(config["batch_size"], ood_len, ood_len)
            dec_inp = torch.cat([inp, tgt[:, :-1]], dim=1)
            x = model.embed(dec_inp)
            for l, block in enumerate(model.blocks):
                x = x + block.attn(block.ln1(x), model.get_mask(dec_inp.size(1)))
                for h, ho in enumerate(block.attn.head_outputs):
                    means[f"L{l}_H{h}"] = means.get(f"L{l}_H{h}", []) + [ho.mean((0,1)).cpu()]
                x = x + block.mlp(block.ln2(x))
    means = {k: torch.stack(v).mean(0).to(device) for k, v in means.items()}

    # Get Effects
    base_acc = compute_accuracy(model, ood_len)
    for k in grads.keys(): # Only ablating heads for speed
        if "MLP" in k: continue
        l, h = int(k[1]), int(k[4])
        # -- Fast manual ablation --
        correct = 0
        for _ in range(50): # N=50 for speed
            inp, tgt = make_batch(1, ood_len, ood_len)
            gen = inp.clone()
            for _ in range(tgt.size(1)):
                x = model.embed(gen)
                mask = model.get_mask(gen.size(1))
                for bl, block in enumerate(model.blocks):
                    ln1 = block.ln1(x)
                    # Manual Attn
                    B, T, D = ln1.shape
                    Q = block.attn.W_q(ln1).view(B, T, 4, 32).transpose(1, 2)
                    K = block.attn.W_k(ln1).view(B, T, 4, 32).transpose(1, 2)
                    V = block.attn.W_v(ln1).view(B, T, 4, 32).transpose(1, 2)
                    sc = (Q @ K.transpose(-2,-1)) / (32**0.5)
                    sc = sc.masked_fill(mask==0, -1e9)
                    att = F.softmax(sc, dim=-1) @ V
                    # INTERVENE
                    if bl == l: att[:, h, :, :] = means[k]
                    x = x + block.attn.W_o(att.transpose(1,2).contiguous().view(B,T,D))
                    x = x + block.mlp(block.ln2(x))
                logits = model.out(model.ln_f(x))
                gen = torch.cat([gen, logits[:,-1].argmax(-1, keepdim=True)], dim=1)
            if gen[0, inp.size(1):].tolist() == tgt[0].tolist(): correct += 1
        causal[k] = base_acc - (correct/50)

    # Identify Bloats
    comps = sorted(grads.keys())
    G = stats.rankdata([grads[c] for c in comps])
    C = stats.rankdata([causal.get(c, 0) for c in comps]) # 0 if MLP skipped
    bloats = [c for c, g, c_r in zip(comps, G, C) if (g - c_r) >= 6 and "MLP" not in c]

    id_base = compute_accuracy(model, 5)


    correct_id = 0
    for _ in range(50):
        inp, tgt = make_batch(1, 5, 5)
        gen = inp.clone()
        for _ in range(tgt.size(1)):
            x = model.embed(gen)
            mask = model.get_mask(gen.size(1))
            for bl, block in enumerate(model.blocks):
                ln1 = block.ln1(x)
                B, T, D = ln1.shape
                Q = block.attn.W_q(ln1).view(B, T, 4, 32).transpose(1, 2)
                K = block.attn.W_k(ln1).view(B, T, 4, 32).transpose(1, 2)
                V = block.attn.W_v(ln1).view(B, T, 4, 32).transpose(1, 2)
                sc = (Q @ K.transpose(-2,-1)) / (32**0.5)
                sc = sc.masked_fill(mask==0, -1e9)
                att = F.softmax(sc, dim=-1) @ V

                for h in range(4):
                    if f"L{bl}_H{h}" in bloats: att[:, h, :, :] = means[f"L{bl}_H{h}"]
                x = x + block.attn.W_o(att.transpose(1,2).contiguous().view(B,T,D))
                x = x + block.mlp(block.ln2(x))
            logits = model.out(model.ln_f(x))
            gen = torch.cat([gen, logits[:,-1].argmax(-1, keepdim=True)], dim=1)
        if gen[0, inp.size(1):].tolist() == tgt[0].tolist(): correct_id += 1

    id_pruned = correct_id / 50

    return {
        "seed": seed, "n_bloats": len(bloats),
        "id_base": id_base, "id_pruned": id_pruned,
        "drop": id_base - id_pruned
    }

results = []
print(f"{'SEED':<6} {'BLOATS':<8} {'ID_BASE':<10} {'ID_PRUNED':<10} {'DROP':<10}")
print("-" * 50)

for seed in SEEDS:
    try:
        res = train_one_seed(seed)
        if res:
            print(f"{res['seed']:<6} {res['n_bloats']:<8} {res['id_base']:<10.1%} {res['id_pruned']:<10.1%} {res['drop']:<10.1%}")
            results.append(res)
        else:
            print(f"{seed:<6} SKIPPED (No OOD len)")
    except Exception as e:
        print(f"{seed:<6} ERROR: {e}")

df = pd.DataFrame(results)
print("\nAVERAGE RESULTS:")
print(f"Mean ID Drop: {df['drop'].mean():.1%} (std {df['drop'].std():.1%})")

"""**F)** Summary"""

# SUMMARY

print(f"\n{'='*60}\nSUMMARY\n{'='*60}")
print(f"""
REVERSE: ρ={rev_rho:.3f}±{np.std([r['rho'] for r in reverse_results]):.3f}, Heroes={sum(len(r['heroes']) for r in reverse_results)}, Bloats={sum(len(r['bloats']) for r in reverse_results)}
SORT:    ρ={sort_rho:.3f}±{np.std([r['rho'] for r in sort_results]):.3f}, Heroes={sum(len(r['heroes']) for r in sort_results)}, Bloats={sum(len(r['bloats']) for r in sort_results)}

PRUNING:
  Reverse: Baseline={reverse_pruning['baseline']:.1%}, Bloats={reverse_pruning['acc_bloats']:.1%}, Heroes={reverse_pruning['acc_heroes']:.1%}
  Sort:    Baseline={sort_pruning['baseline']:.1%}, Bloats={sort_pruning['acc_bloats']:.1%}, Heroes={sort_pruning['acc_heroes']:.1%}

Files saved to: {output_dir}/
""")